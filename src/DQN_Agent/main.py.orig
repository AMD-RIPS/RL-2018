import sys
sys.dont_write_bytecode = True

import sys
import agent
import environment as env
import tensorflow as tf
import hyperparameters.setups as setups 

<<<<<<< b5c981763a79ebb92c861a07dcbef965ff299a47
game = 'CartPole'

environment = env.env_dict[game]()
control = agent.DQN_Agent(environment=environment, model_name=sys.argv[1], **setups.setup_dict[game]['general'])
control.set_training_parameters(**setups.setup_dict[game]['training'])
=======
environment = env.env_dict["CarRacing"](type = "OneCurve", seed = 2)
control = agent.DQN_Agent(environment=environment, architecture='nature', explore_rate='decay', learning_rate='atari', model_name=sys.argv[1])
control.set_training_parameters(discount=.99, batch_size=32, memory_capacity=10000, num_episodes=10000)
# control.load("/home/jguan/Documents/RIPS/RL-2018/src/DQN_Agent/models/carracing_oneturn_1000frames_accumulatereward_blacktile")
>>>>>>> Add in pre training function inside train function and change unit_image to dividing by 255
control.train()
# control.load('/home/pgerber/Documents/RL-2018/src/DQN_Agent/models/tmp/data.chkp')
print(control.test_Q(5, visualize=True))
